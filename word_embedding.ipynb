{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pickle object from `subtitle_processing.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_obj(name):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_obj(\"processed_video_subtitle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles = list(d.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videonames = list(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = subtitles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_word_list(list_of_words):\n",
    "    \"\"\"\n",
    "    Given a list of words, remove stop words, punctuation, and empty strings\n",
    "    \"\"\"\n",
    "    STOPWORDS = stopwords.words(\"english\")\n",
    "    word_list = [w.lower().strip(string.punctuation) for w in list_of_words]\n",
    "    word_list = [w for w in word_list if w not in STOPWORDS and w!='']\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " 'everyone',\n",
       " 'time',\n",
       " 'kizuna',\n",
       " 'ai',\n",
       " 'received',\n",
       " 'work',\n",
       " 'offer',\n",
       " 'bridge',\n",
       " 'connect']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_word_list(test)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_glove(filename):\n",
    "    \"\"\"\n",
    "    Given filename, load glove vector into a dictionary where the key is the word\n",
    "    and the value is a numpy array\n",
    "    \"\"\"\n",
    "\n",
    "    f = open(filename)\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    d = {}\n",
    "\n",
    "    for line in lines:\n",
    "        words = line.split(' ')\n",
    "        word = words[0]\n",
    "        vector = np.array(words[1:], dtype = 'float')\n",
    "        d[word] = vector\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use https://nlp.stanford.edu/projects/glove/ 300-dimensional vectors trained on Wikipedia articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove = load_glove(\"glove.6B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04656  ,  0.21318  , -0.0074364, -0.45854  , -0.035639 ,\n",
       "        0.23643  , -0.28836  ,  0.21521  , -0.13486  , -1.6413   ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['the'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def subtitle2vec(subtitletext, gloves):\n",
    "    \"\"\"\n",
    "    Compute the average word embedding of the subtitles. Note that if the word\n",
    "    is not in the glove dictionary, it will be ignored.\n",
    "    \"\"\"\n",
    "\n",
    "    subtitlevec = [gloves[word] for word in subtitletext if word in gloves]\n",
    "\n",
    "    lengthvec = len(subtitlevec)\n",
    "    centroid = [sum(x)/lengthvec for x in zip(*subtitlevec)]\n",
    "\n",
    "    return centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, subtitle in enumerate(subtitles):\n",
    "    embedding_dict[videonames[i]] = np.array(subtitle2vec(process_word_list(subtitle), glove)).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8936984438988281"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(embedding_dict[videonames[0]], embedding_dict[videonames[1]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cosine_sim(v1,v2):\n",
    "    \"\"\"\n",
    "    Given two numpy arrays, compute cosine similarity and output an integer\n",
    "    \"\"\"\n",
    "    return cosine_similarity(v1, v2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_video(video, n):\n",
    "    \"\"\"\n",
    "    Given a video subtitle file, recommend the closest n video based on the subtitle content\n",
    "    \"\"\"\n",
    "    cosine_sim_list = []\n",
    "    for i, subtitle in enumerate(subtitles):\n",
    "        cosine_sim_list.append(((videonames[i], i), compute_cosine_sim(embedding_dict[video], embedding_dict[videonames[i]])))\n",
    "    \n",
    "    cosine_sim_list.sort(key = lambda x: x[1], reverse = True)\n",
    "    \n",
    "    return video, cosine_sim_list[1:n+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def recommend(select_video, n):\n",
    "    input_video, recommended = closest_video(select_video, n)\n",
    "    print(\"For the video:\" + input_video + \",\")\n",
    "    print(\"https://www.youtube.com/watch?v=\" + re.findall(r'\\-([\\d\\w]+)\\.en.vtt', input_video)[0])\n",
    "    print(\"\\nYour recommended videos are:\\n\")\n",
    "    \n",
    "    for video, score in recommended:\n",
    "        print(\"Video Number %s\" % video[1], ':', video[0], '|', str(np.round(score, 3)))\n",
    "        print(\"https://www.youtube.com/watch?v=\" + re.findall(r'\\-([\\d\\w]+)\\.en.vtt', video[0])[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the video:【ご指名】訪日促進大使、Kizuna AIです！【ありがとうございます】-kebFBXPprIo.en.vtt,\n",
      "https://www.youtube.com/watch?v=kebFBXPprIo\n",
      "\n",
      "Your recommended videos are:\n",
      "\n",
      "Video Number 103 : 仮想少女的懸賞生活！〜バーチャルでも当選できるか？〜 その２-iZykFCJsOks.en.vtt | 0.966\n",
      "https://www.youtube.com/watch?v=iZykFCJsOks \n",
      "\n",
      "Video Number 172 : 【LIVE】A.I.Channel 1st Anniversary!!!【12_1】-1M6J5gIM1Bk.en.vtt | 0.962\n",
      "https://www.youtube.com/watch?v=1M6J5gIM1Bk \n",
      "\n",
      "Video Number 76 : 【未公開】私の素顔大公開！！【NG集】＃129-CrgeWAp19pU.en.vtt | 0.958\n",
      "https://www.youtube.com/watch?v=CrgeWAp19pU \n",
      "\n",
      "Video Number 328 : 【ねんどろいど】１年越しの願いが叶いました！【ついに完成】-_BN5pFwV_k4.en.vtt | 0.957\n",
      "https://www.youtube.com/watch?v=_BN5pFwV_k4 \n",
      "\n",
      "Video Number 168 : 【流行語大賞】私もノミネートされたい！-P1LhzO7PGRg.en.vtt | 0.957\n",
      "https://www.youtube.com/watch?v=P1LhzO7PGRg \n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommend(videonames[0], 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
